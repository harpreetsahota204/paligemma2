{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PaliGemma2-Mix as Remotely Sourced Zoo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "from fiftyone.utils.huggingface import load_from_hub\n",
    "\n",
    "dataset = load_from_hub(\n",
    "    \"voxel51/hand-keypoints\",\n",
    "    name=\"hands_subset\",\n",
    "    max_samples=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For context, here is the first image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.open(dataset.first().filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Zoo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.zoo as foz\n",
    "foz.register_zoo_model_source(\"https://github.com/harpreetsahota204/paligemma2\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foz.download_zoo_model(\n",
    "    \"https://github.com/harpreetsahota204/paligemma2\",\n",
    "    model_name=\"google/paligemma2-10b-mix-448\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.zoo as foz\n",
    "model = foz.load_zoo_model(\n",
    "    \"google/paligemma2-10b-mix-448\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use PaliGemma2-Mix for Captions\n",
    "\n",
    "The three captioning operations require no additional arguments beyond selecting the operation type. \n",
    "\n",
    "Supported `detail_level` values:\n",
    "\n",
    "* `short`\n",
    "\n",
    "*  `coco-style`\n",
    "\n",
    "* `detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"caption\"\n",
    "model.detail_level= \"coco-style\"\n",
    "\n",
    "dataset.apply_model(model, label_field=\"coco_captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['coco_captions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the caption detail level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.detail_level= \"detailed\"\n",
    "\n",
    "dataset.apply_model(model, label_field=\"detailed_captions\")\n",
    "\n",
    "dataset.first()['detailed_captions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use PaliGemma2-Mix for Detection\n",
    "\n",
    "The operations for `detection`, `dense_region_caption`, `region_proposal` don't require additional parameters for general use. \n",
    "\n",
    "However, `open_vocabulary_detection` requires a `text_prompt` parameter to guide the detection towards specific objects. \n",
    "\n",
    "The results are stored as Detections objects containing bounding boxes and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"detection\"\n",
    "\n",
    "model.prompt=[\"person\", \"bookshelf\"] # you can also pass in a string like \"horse; grass; train; sheep; home\"\n",
    "\n",
    "dataset.apply_model(model, label_field=\"detection_results\")\n",
    "\n",
    "dataset.first()['detection_results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use PaliGemm2-Mix for Segmentation\n",
    "\n",
    "Segmentation requires either a direct expression or a reference to a field containing expressions. \n",
    "\n",
    "Similar to phrase grounding, you can provide this in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"segment\"\n",
    "\n",
    "model.prompt= [\"person relaxing\", \"person playing sports\", \"person talking\"] #could pass a list of strings or a string delimited by , or ;\n",
    "\n",
    "dataset.apply_model(model, label_field=\"segment_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['segment_results']['detections'][0]['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "mask = dataset.first()['segment_results']['detections'][0]['mask']\n",
    "mask_image = Image.fromarray(mask)\n",
    "# mask_image = mask_image.resize((mask.shape[1], mask.shape[0]))  # Resize to match input mask dimensions\n",
    "mask_image.save('segmentation_mask.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use PaliGemm2-Mix for OCR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"ocr\"\n",
    "\n",
    "dataset.apply_model(model, label_field=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use PaliGemm2-Mix for Zero-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"classify\"\n",
    "\n",
    "model.prompt=[\"a person doing yoga\", \"a person playing sports\", \"a person talking to someone\", \"people working\"]\n",
    "\n",
    "dataset.apply_model(model, label_field=\"classify_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['classify_results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use PaliGemm2-Mix for Answering Questions\n",
    "\n",
    "Note: This will parse output as a FiftyOne Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.operation=\"answer\"\n",
    "\n",
    "model.prompt=\"What activity are the people doing?\"\n",
    "\n",
    "dataset.apply_model(model, label_field=\"answer_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.first()['answer_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
